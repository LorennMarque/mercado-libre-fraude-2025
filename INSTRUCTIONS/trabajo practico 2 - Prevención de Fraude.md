# üéì TRABAJO PR√ÅCTICO 2
## Detecci√≥n de Fraude con Machine Learning

**Asignatura**: Taller de Resoluci√≥n de Problemas II  
**Tema**: An√°lisis y Modelado de Datos Desbalanceados  
**Modalidad**: Trabajo grupal 
**Fecha de entrega**: 14 de noviembre a presentar en la oficina de Mercado Libre

---

## üìã √çNDICE

1. [Introducci√≥n](#introducci√≥n)
2. [Objetivos de Aprendizaje](#objetivos-de-aprendizaje)
3. [Contexto del Problema](#contexto-del-problema)
4. [Dataset Proporcionado](#dataset-proporcionado)
5. [Consignas del Trabajo](#consignas-del-trabajo)
6. [Criterios de Evaluaci√≥n](#criterios-de-evaluaci√≥n)
7. [Entregables](#entregables)
8. [Recursos Disponibles](#recursos-disponibles)
9. [Cronograma Sugerido](#cronograma-sugerido)
10. [Preguntas Frecuentes](#preguntas-frecuentes)

---

## üéØ INTRODUCCI√ìN

El fraude en transacciones financieras representa uno de los desaf√≠os m√°s importantes para las empresas de comercio electr√≥nico y fintech. Detectar transacciones fraudulentas en tiempo real es crucial para:

- **Proteger a los clientes** de cargos no autorizados
- **Minimizar p√©rdidas econ√≥micas** de la empresa
- **Mantener la confianza** en la plataforma

Sin embargo, este problema presenta un desaf√≠o t√©cnico significativo: **los datasets de fraude son altamente desbalanceados**. En un escenario t√≠pico, solo el 1-5% de las transacciones son fraudulentas, mientras que el 95-99% son leg√≠timas.

Este trabajo pr√°ctico te desaf√≠a a desarrollar un sistema de detecci√≥n de fraude utilizando t√©cnicas de machine learning, enfrentando los desaf√≠os reales que encontrar√≠as en la industria.

---

## üéì OBJETIVOS DE APRENDIZAJE

Al completar este trabajo pr√°ctico, ser√°s capaz de:

### Objetivos T√©cnicos
- ‚úÖ Identificar y analizar datasets desbalanceados
- ‚úÖ Aplicar t√©cnicas de preprocesamiento de datos (limpieza, encoding, normalizaci√≥n)
- ‚úÖ Implementar t√©cnicas de balanceo (SMOTE, class weights, undersampling)
- ‚úÖ Desarrollar modelos de clasificaci√≥n supervisada
- ‚úÖ Evaluar modelos con m√©tricas apropiadas para datos desbalanceados
- ‚úÖ Optimizar umbrales de decisi√≥n seg√∫n objetivos de negocio
- ‚úÖ Realizar feature engineering para mejorar el rendimiento

### Objetivos de Negocio
- ‚úÖ Interpretar resultados en contexto real
- ‚úÖ Calcular y minimizar costos de negocio (FP vs FN)
- ‚úÖ Comunicar hallazgos de manera clara y profesional
- ‚úÖ Tomar decisiones basadas en datos

---

## üè¢ CONTEXTO DEL PROBLEMA

### Escenario

Trabajas como Data Scientist en **Mercado Libre**, una empresa de e-commerce en Latinoam√©rica. La empresa procesa aproximadamente muchas transacciones, pero enfrenta un de fraude (por el volumen de transacciones y su atractivo para ser atacada).

### Tu Misi√≥n

El equipo directivo te ha encomendado desarrollar un **modelo de machine learning** que:

1. **Maximice la detecci√≥n de fraudes** (recall alto)
2. **Minimice las falsas alarmas** (precision razonable)
3. **Reduzca los costos totales** del sistema (FP + FN)
4. **Sea interpretable y justificable** para el equipo de negocio
5. **Que sugieras cualquier otra mejora** para enriquecer la detecci√≥n de fraude

### Costos de Negocio

```
False Positive (FP): Bloquear transacci√≥n leg√≠tima
‚îú‚îÄ‚îÄ Llamada de verificaci√≥n al cliente
‚îú‚îÄ‚îÄ Tiempo de atenci√≥n al cliente
‚îú‚îÄ‚îÄ Posible p√©rdida de venta
‚îî‚îÄ‚îÄ Costo estimado: $5 por FP (si solo tenemos en cuenta el costo del contacto y no los efetos de marca o reputacionales, el churn, etc.)

False Negative (FN): Fraude no detectado
‚îú‚îÄ‚îÄ P√©rdida del monto de transacci√≥n
‚îú‚îÄ‚îÄ Cargo de vuelta (chargeback)
‚îú‚îÄ‚îÄ Tarifa de procesamiento del banco
‚îú‚îÄ‚îÄ Investigaci√≥n del caso
‚îî‚îÄ‚îÄ Costo estimado: $200 por FN

Ratio de costo: FN:FP = 40:1 (con los assumptions anteriores)
```

**Objetivo de negocio**: Minimizar el costo total mensual de errores.

---

## üìä DATASET PROPORCIONADO

### Descripci√≥n General

**Archivo**: `01_datos/fraud_dataset_v2.csv`

- **Registros**: 250,000 transacciones
- **Per√≠odo**: 4 meses (Marzo - Abril 2020)
- **Regi√≥n**: Principalmente Brasil (74%) y Argentina (21%)
- **Desbalance**: 97% no fraude (242,498) vs **3% fraude (7,502)**
- **Ratio**: 32:1 (clase mayoritaria:minoritaria)

### Variables del Dataset

#### Variable Objetivo
- **`fraude`**: {0 = No Fraude, 1 = Fraude}

#### Variables de Entrada (Features)

**Variables Num√©ricas** (16 columnas):
| Variable | Tipo | Descripci√≥n | Rango |
|----------|------|-------------|-------|
| `monto` | float | Monto de la transacci√≥n | $0.02 - $3,696 |
| `score` | int | Score de riesgo del sistema actual | 0-100 |
| `a`, `b`, `c`, `d`, `e`, `f`, `h`, `k`, `l`, `m`, `n`, `q`, `r`, `s` | float/int | Variables anonimizadas de comportamiento | Variado |

**Variables Categ√≥ricas** (7 columnas):
| Variable | Tipo | Descripci√≥n | Valores √önicos |
|----------|------|-------------|----------------|
| `g` | string | Pa√≠s de la transacci√≥n | 51 pa√≠ses |
| `i` | string | ID de producto | 127,804 productos |
| `j` | string | Categor√≠a de producto | 8,324 categor√≠as |
| `o` | string | Variable binaria Y/N | 2 valores |
| `p` | string | Variable binaria Y/N | 2 valores |
| `fecha` | datetime | Timestamp de transacci√≥n | 145,813 valores √∫nicos |

**‚ö†Ô∏è Nota**: Algunas variables contienen valores faltantes (NaN) que deber√°s manejar apropiadamente.

---

## üìù CONSIGNAS DEL TRABAJO

El trabajo est√° dividido en **6 secciones obligatorias** y **1 secci√≥n opcional** para destacarse.

---

### **PARTE 1: An√°lisis Exploratorio de Datos (EDA)** - 15 puntos

#### Objetivos
Comprender en profundidad el dataset y el problema de desbalance.

#### Tareas Requeridas

**1.1. Exploraci√≥n B√°sica**
- Cargar el dataset y mostrar informaci√≥n general (shape, tipos de datos, valores faltantes)
- Calcular estad√≠sticas descriptivas de variables num√©ricas
- Identificar y cuantificar el desbalance de clases
- Visualizar la distribuci√≥n de la variable objetivo

**1.2. An√°lisis de Variables**
- Analizar distribuci√≥n de variables num√©ricas (histogramas, boxplots)
- Analizar variables categ√≥ricas (frecuencias, top valores)
- Identificar outliers en variables num√©ricas
- Analizar correlaciones entre variables num√©ricas

**1.3. An√°lisis del Fraude**
- Comparar caracter√≠sticas de transacciones fraudulentas vs normales
- Identificar variables con mayor diferencia entre clases
- Analizar patrones temporales (hora del d√≠a, d√≠a de semana)
- Analizar distribuci√≥n geogr√°fica del fraude

**Entregable**: Notebook con visualizaciones y conclusiones del EDA.

---

### **PARTE 2: Preprocesamiento de Datos**

#### Objetivos
Preparar el dataset para el modelado, manejando apropiadamente los desaf√≠os presentes.

#### Tareas Requeridas

**2.1. Manejo de Valores Faltantes**
- Analizar el patr√≥n de valores faltantes
- Implementar estrategia de imputaci√≥n justificada
- Documentar decisiones tomadas

**2.2. Feature Engineering**
- Extraer features temporales de la variable `fecha`:
  - Hora del d√≠a
  - D√≠a de la semana
  - Es fin de semana (binaria)
  - Es horario nocturno (binaria)
  - D√≠a del mes
- Crear features adicionales (ratios, agregaciones, etc.)

**2.3. Encoding de Variables Categ√≥ricas**
- Implementar encoding apropiado para variables categ√≥ricas
- Manejar variables de alta cardinalidad (`i`, `j`)
- Justificar la elecci√≥n de t√©cnica de encoding

**2.4. Split Train/Test**
- Dividir dataset en train (80%) y test (20%)
- Verificar que el desbalance se mantiene en ambos sets

**Entregable**: C√≥digo documentado de preprocesamiento y dataset procesado.

---

### **PARTE 3: Modelo Baseline**

#### Objetivos
Desarrollar un modelo baseline que sirva como punto de comparaci√≥n.

#### Tareas Requeridas

**3.1. Entrenamiento del Modelo Baseline**
- Entrenar un modelo de clasificaci√≥n **sin t√©cnicas de balanceo avanzadas**
- Algoritmos sugeridos: Random Forest, Logistic Regression, o XGBoost
- Usar `class_weight='balanced'` (o equivalente) como t√©cnica b√°sica

**3.2. Evaluaci√≥n con M√©tricas Apropiadas**
- **NO usar Accuracy** como m√©trica principal
- Calcular y reportar:
  - **Confusion Matrix** (interpretar cada cuadrante)
  - **Recall** (m√©trica principal para fraude)
  - **Precision**
  - **F1-Score**
  - **AUC-ROC**
  - **AUC-PR** (Precision-Recall Curve)
- Visualizar curvas ROC y Precision-Recall

**3.3. Interpretaci√≥n de Resultados**
- Explicar qu√© significan los resultados en contexto de negocio
- Identificar el principal problema del modelo baseline
- Calcular el costo total de errores (FP √ó $5 + FN √ó $200)

**Entregable**: Modelo baseline entrenado, m√©tricas calculadas e interpretadas.

---

### **PARTE 4: T√©cnicas de Balanceo**

#### Objetivos
Implementar y comparar t√©cnicas avanzadas para manejar el desbalance.

#### Tareas Requeridas

**4.1. SMOTE (Synthetic Minority Over-sampling Technique)**
- Implementar SMOTE en el **conjunto de train** √∫nicamente
- ‚ö†Ô∏è **IMPORTANTE**: Aplicar SMOTE **DESPU√âS** del train/test split (evitar data leakage)
- Verificar el nuevo balance de clases
- Entrenar modelo con datos balanceados
- Evaluar con las mismas m√©tricas que el baseline

**4.2. T√©cnica Adicional de Balanceo**
Implementar **al menos una** de las siguientes:
- **Undersampling** de la clase mayoritaria
- **Combinaci√≥n** de SMOTE + Undersampling (SMOTETomek, SMOTEENN)
- **Ensemble con balanceo**: BalancedRandomForest
- **Ajuste de class_weight** optimizado

**4.3. Comparaci√≥n de T√©cnicas**
- Crear tabla comparativa de resultados:
- Analizar trade-offs (precision vs recall)
- Justificar cu√°l t√©cnica es m√°s apropiada para el negocio

**Entregable**: Modelos con diferentes t√©cnicas de balanceo, comparaci√≥n de resultados.

---

### **PARTE 5: Optimizaci√≥n de Threshold**

#### Objetivos
Optimizar el umbral de decisi√≥n para maximizar el objetivo de negocio.

#### Tareas Requeridas

**5.1. B√∫squeda de Threshold √ìptimo**
- Probar diferentes valores de threshold (0.1, 0.15, 0.2, ..., 0.9)
- Para cada threshold, calcular:
  - Confusion matrix
  - Precision, Recall, F1-Score
  - Costo total de negocio
- Visualizar c√≥mo var√≠an las m√©tricas seg√∫n el threshold

**5.2. Selecci√≥n del Threshold √ìptimo**
Justificar la elecci√≥n del threshold √≥ptimo seg√∫n **dos criterios**:
1. **Maximizar F1-Score** (balance precision-recall)
2. **Minimizar costo total de negocio**

Nota: Ambos criterios pueden dar thresholds diferentes. Discutir las implicaciones.


**Entregable**: An√°lisis de threshold optimization con visualizaciones y recomendaci√≥n final.

---

### **PARTE 6: Presentar todo**

#### Objetivos
Poder comunicar lo que hicieron

#### Tareas Requeridas

**6.1 Preparar una presentaci√≥n de todo lo que hicieron que se entrega en vivo el 14 de noviembre (lo presentan)**. Tener en cuenta:
- Contar lo que hicieron en forma m√°s sintetica que con los notebooks
- Tener el material t√©cnico a mano para acceder
- Usar recursos visuales que ayuden y ejemplos que lo bajen a tierra
- Contar que cosas extras hubiesen hecho

**Entregable**: Presentaci√≥n y Secci√≥n de conclusiones y recomendaciones en el informe final.

### Recursos Externos Recomendados

#### Documentaci√≥n Oficial
- [Scikit-learn: Imbalanced Data](https://scikit-learn.org/stable/modules/cross_validation.html#stratification)
- [Imbalanced-learn Documentation](https://imbalanced-learn.org/stable/)
- [SMOTE Paper Original](https://arxiv.org/abs/1106.1813)

#### Tutoriales
- [Machine Learning Mastery: Imbalanced Classification](https://machinelearningmastery.com/what-is-imbalanced-classification/)
- [Towards Data Science: Dealing with Imbalanced Data](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18)
